{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcffa12b-7163-48fd-b597-b2303a24a583",
   "metadata": {},
   "source": [
    "## Deviations in model peformances\n",
    "\n",
    "For the estimation of congruence values. TODO: insert Ref\n",
    "\n",
    "Start this notebook inside a new environment after installing the necessary dependencies, e.g., \n",
    "\n",
    "```commandline\n",
    "conda create --name deviations python=3.10\n",
    "conda activate deviations\n",
    "pip install mml-core mml-tasks\n",
    "```\n",
    "\n",
    "Make sure to set your `mml` environment variables, e.g., \n",
    "\n",
    "```commandline\n",
    "cd ~/.config\n",
    "mml-env-setup\n",
    "nano mm.env\n",
    "```\n",
    "\n",
    "You can follow [the docs](https://mml.readthedocs.io/en/latest/install.html#setting-the-variables) for this. Do not forget to navigate back to this notebook's folder before starting the server.\n",
    "\n",
    "```commandline\n",
    "cd PATH/TO/THIS/NOTEBOOKS/PARENT\n",
    "jupyter notebook\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb5433e-127d-4a1a-9996-1e66b8e3466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____ ______   _____ ______   ___\n",
      "|\\   _ \\  _   \\|\\   _ \\  _   \\|\\  \\\n",
      "\\ \\  \\\\\\__\\ \\  \\ \\  \\\\\\__\\ \\  \\ \\  \\\n",
      " \\ \\  \\\\|__| \\  \\ \\  \\\\|__| \\  \\ \\  \\\n",
      "  \\ \\  \\    \\ \\  \\ \\  \\    \\ \\  \\ \\  \\____\n",
      "   \\ \\__\\    \\ \\__\\ \\__\\    \\ \\__\\ \\_______\\\n",
      "    \\|__|     \\|__|\\|__|     \\|__|\\|_______|\n",
      "         ____  _  _    __  _  _  ____  _  _\n",
      "        (  _ \\( \\/ )  (  )( \\/ )/ ___)( \\/ )\n",
      "         ) _ ( )  /    )( / \\/ \\\\___ \\ )  /\n",
      "        (____/(__/    (__)\\_)(_/(____/(__/\n",
      "Interactive MML API initialized.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import mml.interactive\n",
    "# assuming the mml.env location as described above\n",
    "mml.interactive.init(Path('~/.config/mml.env').expanduser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98456a0a-ac76-4bfd-8101-81ceb5dcbf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 1: Task selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ef018d-b13b-48d5-a28a-9eaa1b584f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Started with all 81 tasks, as used in [Task fingrprinting](https://arxiv.org/abs/2412.08763)\n",
    "all_tasks = (\n",
    "    'lapgyn4_anatomical_structures', 'lapgyn4_surgical_actions', 'lapgyn4_instrument_count',\n",
    "    'lapgyn4_anatomical_actions',\n",
    "    'sklin2_skin_lesions', 'identify_nbi_infframes', 'laryngeal_tissues', 'nerthus_bowel_cleansing_quality',\n",
    "    'stanford_dogs_image_categorization', 'svhn', 'caltech101_object_classification',\n",
    "    'caltech256_object_classification',\n",
    "    'cifar10_object_classification', 'cifar100_object_classification', 'mnist_digit_classification',\n",
    "    'emnist_digit_classification', 'hyperkvasir_anatomical-landmarks', 'hyperkvasir_pathological-findings',\n",
    "    'hyperkvasir_quality-of-mucosal-views', 'hyperkvasir_therapeutic-interventions', 'cholec80_grasper_presence',\n",
    "    'cholec80_bipolar_presence', 'cholec80_hook_presence', 'cholec80_scissors_presence', 'cholec80_clipper_presence',\n",
    "    'cholec80_irrigator_presence', 'cholec80_specimenbag_presence', 'derm7pt_skin_lesions',\n",
    "    'idle_action_recognition', 'barretts_esophagus_diagnosis', 'brain_tumor_classification',\n",
    "    'mednode_melanoma_classification', 'brain_tumor_type_classification',\n",
    "    'chexpert_enlarged_cardiomediastinum', 'chexpert_cardiomegaly', 'chexpert_lung_opacity',\n",
    "    'chexpert_lung_lesion', 'chexpert_edema', 'chexpert_consolidation', 'chexpert_pneumonia',\n",
    "    'chexpert_atelectasis', 'chexpert_pneumothorax', 'chexpert_pleural_effusion', 'chexpert_pleural_other',\n",
    "    'chexpert_fracture', 'chexpert_support_devices',\n",
    "    'pneumonia_classification', 'ph2-melanocytic-lesions-classification',\n",
    "    'covid_xray_classification', 'isic20_melanoma_classification', 'deep_drid_dr_level',\n",
    "    'shenzen_chest_xray_tuberculosis', 'crawled_covid_ct_classification', 'deep_drid_quality',\n",
    "    'deep_drid_clarity', 'deep_drid_field', 'deep_drid_artifact', 'kvasir_capsule_anatomy',\n",
    "    'kvasir_capsule_content', 'kvasir_capsule_pathologies',\n",
    "    'breast_cancer_classification_v2',\n",
    "    'eye_condition_classification', 'mura_xr_wrist', 'mura_xr_shoulder', 'mura_xr_humerus', 'mura_xr_hand',\n",
    "    'mura_xr_forearm', 'mura_xr_finger', 'mura_xr_elbow',\n",
    "    'bean_plant_disease_classification',\n",
    "    'aptos19_blindness_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73d766-e680-4ec9-92b3-7d15ec6dfc31",
   "metadata": {},
   "source": [
    "The goal was to have a subset of tasks that encompasses a high variety in properties, while allowing the distinction of models. Thus we first exclude some easier tasks (AUROC > 0.95) on some baseline runs. Out of the 36 tasks that meet this exclusion criterion we keep 2 for the variability reason. One was chosen explicitely for the CT modality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb257759-3c5a-4b37-9199-492c0515ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'x_ray': 20,\n",
       "         'fundus_photography': 6,\n",
       "         'dermatoscopy': 5,\n",
       "         'gastroscopy_colonoscopy': 2,\n",
       "         'confocal laser endomicroscopy': 1,\n",
       "         'ct_scan': 1,\n",
       "         'ultrasound': 1,\n",
       "         'cataract_surgery': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_tasks = ('lapgyn4_anatomical_structures',\n",
    "              'lapgyn4_surgical_actions',\n",
    "              'lapgyn4_instrument_count',\n",
    "              'lapgyn4_anatomical_actions',\n",
    "              'identify_nbi_infframes',\n",
    "              'laryngeal_tissues',\n",
    "              'nerthus_bowel_cleansing_quality',\n",
    "              'stanford_dogs_image_categorization',\n",
    "              'svhn',\n",
    "              'caltech101_object_classification',\n",
    "              'caltech256_object_classification',\n",
    "              'cifar10_object_classification',\n",
    "              'cifar100_object_classification',\n",
    "              'mnist_digit_classification',\n",
    "              'emnist_digit_classification',\n",
    "              # 'hyperkvasir_anatomical-landmarks', # we want to add some easy tasks\n",
    "              'hyperkvasir_quality-of-mucosal-views',\n",
    "              'hyperkvasir_therapeutic-interventions',\n",
    "              'cholec80_grasper_presence',\n",
    "              'cholec80_bipolar_presence',\n",
    "              'cholec80_hook_presence',\n",
    "              'cholec80_scissors_presence',\n",
    "              'cholec80_clipper_presence',\n",
    "              'cholec80_irrigator_presence',\n",
    "              'cholec80_specimenbag_presence',\n",
    "              'idle_action_recognition',\n",
    "              'brain_tumor_classification',\n",
    "              'brain_tumor_type_classification',\n",
    "              'pneumonia_classification',\n",
    "              'covid_xray_classification',\n",
    "              'shenzen_chest_xray_tuberculosis',\n",
    "              # 'crawled_covid_ct_classification',  # we want to add some easy tasks, ct will make it as unique modality\n",
    "              'kvasir_capsule_anatomy',\n",
    "              'kvasir_capsule_content',\n",
    "              'kvasir_capsule_pathologies',\n",
    "              'bean_plant_disease_classification')  \n",
    "# we further reduce to medical tasks\n",
    "realistic_tasks = [t for t in all_tasks if t not in easy_tasks]\n",
    "infos = mml.interactive.get_task_infos(task_list=realistic_tasks)\n",
    "medical_tasks = [t for t in realistic_tasks if infos.domains[t] not in ['natural_objects', 'handwritings']]\n",
    "infos = mml.interactive.get_task_infos(task_list=medical_tasks)\n",
    "Counter(infos.domains.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e8e501f-2c09-4b31-b2ee-c07e937372a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eye_condition_classification',\n",
       " 'barretts_esophagus_diagnosis',\n",
       " 'crawled_covid_ct_classification',\n",
       " 'derm7pt_skin_lesions',\n",
       " 'deep_drid_quality',\n",
       " 'hyperkvasir_anatomical-landmarks',\n",
       " 'breast_cancer_classification_v2',\n",
       " 'mura_xr_forearm']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we start by selecting one task per imaging modality\n",
    "import random\n",
    "final_tasks = []\n",
    "random.seed(42)\n",
    "for dom in sorted(list(set(infos.domains.values()))):\n",
    "    all_dom_tasks = [t for t in medical_tasks if infos.domains[t] == dom]\n",
    "    final_tasks.append(random.choice(all_dom_tasks))\n",
    "final_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c24603-c04d-4911-82da-57568ad92598",
   "metadata": {},
   "source": [
    "From here we pause and analyse the choices on variability of further properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c8ed7a-31dc-4ee8-bdc7-05d0c6aed84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 3, 3: 2, 4: 1, 5: 1, 6: 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 out of 8 are binary, will add 3 more binary and one multiclass by random \n",
    "Counter([infos.num_classes[t] for t in final_tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c334da6-3014-496f-a321-6276905458c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({601: 1, 262: 1, 746: 1, 616: 1, 1200: 1, 4104: 1, 780: 1, 1825: 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rather small tasks so far\n",
    "Counter([infos.num_samples[t] for t in final_tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a16925-9736-4f90-942d-1d77015df6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3.0: 1,\n",
       "         5.733333333333333: 1,\n",
       "         1.1375358166189111: 1,\n",
       "         13.692307692307692: 1,\n",
       "         1.0833333333333333: 1,\n",
       "         112.11111111111111: 1,\n",
       "         3.2857142857142856: 1,\n",
       "         1.7609682299546143: 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-uniform class imbalance so far\n",
    "Counter([infos.imbalance_ratios[t] for t in final_tasks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5a0d7a1-2a10-4cf9-96e3-6b25e539dc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aptos19_blindness_detection']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = [t for t in medical_tasks if t not in final_tasks]\n",
    "binary_cands = [t for t in candidates if infos.num_classes[t] == 2]\n",
    "multi_cands = [t for t in candidates if infos.num_classes[t] != 2]\n",
    "# only one imbalanced multiclass candidate\n",
    "[t for t in multi_cands if infos.imbalance_ratios[t] > 2 and infos.num_samples[t] > 3_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2457cc94-f87c-4a11-80f6-21d217fbc633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chexpert_enlarged_cardiomediastinum',\n",
       " 'chexpert_cardiomegaly',\n",
       " 'chexpert_lung_opacity',\n",
       " 'chexpert_lung_lesion',\n",
       " 'chexpert_edema',\n",
       " 'chexpert_atelectasis',\n",
       " 'chexpert_pneumothorax',\n",
       " 'chexpert_pleural_effusion',\n",
       " 'chexpert_fracture',\n",
       " 'chexpert_support_devices',\n",
       " 'isic20_melanoma_classification']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the binary candidates that are imbalanced and large\n",
    "[t for t in binary_cands if infos.imbalance_ratios[t] > 2 and infos.num_samples[t] > 10_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d5925b-5df6-4164-b14e-12b369feb945",
   "metadata": {},
   "source": [
    "Take ISIC as given for its idependence from the others. Now we need to choose two tasks from the CheXpert dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87178fa4-5545-4c6d-9ffa-1c8d0ee5e5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chexpert_cardiomegaly'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(['chexpert_enlarged_cardiomediastinum',\n",
    "               'chexpert_cardiomegaly',\n",
    "               'chexpert_lung_opacity',\n",
    "               'chexpert_lung_lesion',\n",
    "               'chexpert_edema',\n",
    "               'chexpert_atelectasis',\n",
    "               'chexpert_pneumothorax',\n",
    "               'chexpert_pleural_effusion',\n",
    "               'chexpert_fracture',\n",
    "               'chexpert_support_devices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "813c1f92-a276-41b8-9a96-3de633a3b712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chexpert_pleural_effusion'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(['chexpert_enlarged_cardiomediastinum',\n",
    "               'chexpert_lung_opacity',\n",
    "               'chexpert_lung_lesion',\n",
    "               'chexpert_edema',\n",
    "               'chexpert_atelectasis',\n",
    "               'chexpert_pneumothorax',\n",
    "               'chexpert_pleural_effusion',\n",
    "               'chexpert_fracture',\n",
    "               'chexpert_support_devices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57bc81a8-35cb-4b41-a99d-84c792db95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the final task list\n",
    "final_tasks = ['eye_condition_classification',       # by domain (not easy)\n",
    "               'barretts_esophagus_diagnosis',       # by domain (not easy)\n",
    "               'crawled_covid_ct_classification',    # by domain (easy)\n",
    "               'derm7pt_skin_lesions',               # by domain (not easy)\n",
    "               'deep_drid_quality',                  # by domain (not easy)\n",
    "               'hyperkvasir_anatomical-landmarks',   # by domain (easy)\n",
    "               'breast_cancer_classification_v2',    # by domain (not easy)\n",
    "               'mura_xr_forearm',                    # by domain (not easy)\n",
    "               'chexpert_cardiomegaly',              # binary, imbalanced, large\n",
    "               'chexpert_pleural_effusion',          # binary, imbalanced, large\n",
    "               'isic20_melanoma_classification',     # binary, imbalanced, large\n",
    "               'aptos19_blindness_detection']        # multiclass, imbalanced, large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c01f59-4902-429c-b189-bf02a0fb1d56",
   "metadata": {},
   "source": [
    "### Part 2: Model training sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4299900e-7300-484e-9d67-9347c45c4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mml.interactive import MMLJobDescription, SubprocessJobRunner, DefaultRequirements\n",
    "\n",
    "reqs = DefaultRequirements()\n",
    "# the 5 models we investigate\n",
    "models_list = ['caformer_s36.sail_in22k_ft_in1k', \n",
    "               'tiny_vit_21m_224.dist_in22k_ft_in1k', \n",
    "               'swin_s3_small_224.ms_in1k',\n",
    "               'coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k', \n",
    "               'resnext101_32x4d.fb_swsl_ig1b_ft_in1k']\n",
    "# the mathcing batch sizes that fit to our hardware\n",
    "batch_size_list =  [50, 200, 100, 100, 200]\n",
    "# we test three very different augmentation strategies for optimization\n",
    "augmentations_list = ['basic', 'randaugment', 'load_imagenet_aa']\n",
    "# we test for both class balanced sampling during training and prevalence preserving sampling\n",
    "balanced_sampling_list = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e907f1a-654a-47c6-86eb-07268d7a9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "job_list = []\n",
    "for task in final_tasks:\n",
    "    for model, b_size in zip(models_list, batch_size_list):\n",
    "        for augmentation in augmentations_list:\n",
    "            for sampling in balanced_sampling_list:\n",
    "                job_list.append(\n",
    "                    MMLJobDescription(prefix_req=reqs, mode='train', config_options={\n",
    "                                'proj': 'eva_deviations',\n",
    "                                'mode.subroutines': ['train', 'predict'],\n",
    "                                'pivot.name': task,\n",
    "                                'arch.name': model,\n",
    "                                'mode.cv': False,                     # no cross validation\n",
    "                                'mode.nested': True,                  # use the original val split as test, separate a new val split from train\n",
    "                                'sampling.balanced': sampling,\n",
    "                                'loss.auto_activate_weighing': False, # to prevent loss weighting for class preservation\n",
    "                                'sampling.batch_size': b_size,       \n",
    "                                'callbacks': ['early', 'default'],    # early stopping\n",
    "                                'lr_scheduler': 'plateau',            # reduce LR on plateau\n",
    "                                'trainer.max_epochs': 40,             # maximum epochs\n",
    "                                'augmentations': augmentation,        \n",
    "                                'preprocessing': 'size224',           # name of the preprocessing pipeline\n",
    "                                'sampling.enable_caching': True,      # enable image sample caching for efficiency\n",
    "                                'reuse.clean_up.parameters': True,    # no need to permanently store model parameters\n",
    "                                'optimizer': 'adam',                  # Adam optimizer\n",
    "                            }))\n",
    "print(len(job_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "296390e6-a2b9-48e4-976b-400fede3e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a job like this (commented to prevent accidental triggering)\n",
    "runner = SubprocessJobRunner()\n",
    "# for job in job_list:\n",
    "#     runner.run(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dad2ac-63b6-4fcc-b631-5ceed20a6e86",
   "metadata": {},
   "source": [
    "### Part 3: Selection of best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36ff48e5-ab31-4d44-8348-1d2dcdccdd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c568b990-dbfe-4fe0-979a-ef31fc9fecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all information, to be found in \"infos.csv\"\n",
    "information = []\n",
    "sub_tasks = [t + '+nested?0' for t in final_tasks]\n",
    "sub_infos = mml.interactive.get_task_infos(sub_tasks)\n",
    "structs = mml.interactive.get_task_structs(sub_tasks)\n",
    "for struct in structs:\n",
    "    information.append({'name': struct.name, 'train+val': sub_infos.num_samples[struct.name], 'classes': struct.num_classes, 'keywords': struct.keywords, 'ir': sub_infos.imbalance_ratios[struct.name]})\n",
    "infos_df = pd.DataFrame(information)\n",
    "infos_df.to_csv('infos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29d1b9cb-a922-43ae-b9a5-df4dee56216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = mml.interactive.load_project_models('eva_deviations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82daf80a-bf68-4369-92a1-ceaaf0f337d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reroute_path(p: Path, relative: bool = False) -> Path:\n",
    "    \"\"\"Small helper to resolve all pathing issues from varying systems\"\"\"\n",
    "    new_root = Path(os.getenv('MML_RESULTS_PATH'))\n",
    "    project_index_in_path = [q.name for q in p.parents].index('eva_deviations')\n",
    "    remainder = p.relative_to(p.parents[project_index_in_path])\n",
    "    return Path('eva_deviations') / remainder if relative else new_root / 'eva_deviations' / remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ed035b5-e8b1-4839-89d3-41c71a4db78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather overview on all runs\n",
    "run_infos = []\n",
    "task_arch_container = {}\n",
    "for task in all_models:\n",
    "    for model in all_models[task]:\n",
    "        pipeline = OmegaConf.load(reroute_path(model.pipeline))\n",
    "        run_infos.append({\n",
    "            'task': task,\n",
    "            'architecture': pipeline.arch.name,\n",
    "            'balanced_sampling': pipeline.sampling.balanced,\n",
    "            'batch_size': pipeline.sampling.batch_size,\n",
    "            'lr_scheduler': pipeline.lr_scheduler._target_.split('.')[-1],\n",
    "            'augmentations': pipeline.augmentations.cpu.pipeline[0].name,\n",
    "            'optimizer': pipeline.optimizer._target_.split('.')[-1],\n",
    "            'predictions': reroute_path(model.predictions[task + '-test-0'], relative=True)\n",
    "        })\n",
    "        if (pipeline.arch.name, task) not in task_arch_container:\n",
    "            task_arch_container[(pipeline.arch.name, task)] = [model]\n",
    "        else:\n",
    "            task_arch_container[(pipeline.arch.name, task)].append(model)\n",
    "pd.DataFrame(run_infos).to_csv('run_infos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f39783fb-3b66-4031-a8a6-2791c410c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no legal models for chexpert_pleural_effusion+nested?0/resnext101_32x4d.fb_swsl_ig1b_ft_in1k\n"
     ]
    }
   ],
   "source": [
    "# select best augmentation and sampling strategy based on validation performance\n",
    "best_infos = []\n",
    "for arch, task in task_arch_container:\n",
    "    legal_models = [m for m in task_arch_container[(arch, task)] if m.performance is not None]\n",
    "    if len(legal_models) == 0:\n",
    "        # in one case no sampling strategy lead to convergence of model training\n",
    "        print(f'no legal models for {task}/{arch}')\n",
    "        continue\n",
    "    model = sorted(legal_models, key=lambda x: x.performance)[0]\n",
    "    pipeline = OmegaConf.load(reroute_path(model.pipeline))\n",
    "    best_infos.append({\n",
    "        'task': task,\n",
    "        'architecture': pipeline.arch.name,\n",
    "        'balanced_sampling': pipeline.sampling.balanced,\n",
    "        'batch_size': pipeline.sampling.batch_size,\n",
    "        'lr_scheduler': pipeline.lr_scheduler._target_.split('.')[-1],\n",
    "        'augmentations': pipeline.augmentations.cpu.pipeline[0].name,\n",
    "        'optimizer': pipeline.optimizer._target_.split('.')[-1],\n",
    "        'predictions': reroute_path(model.predictions[task + '-test-0'], relative=True)\n",
    "    })\n",
    "pd.DataFrame(best_infos).to_csv('best_runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f88f0-ad47-4068-a3ed-066157e36759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
